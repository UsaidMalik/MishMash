{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing my libraries"
      ],
      "metadata": {
        "id": "12hlOUtu6hBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md\n",
        "!python -m spacy download fr_core_news_md\n",
        "#!pip install cupy\n",
        "\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import spacy\n",
        "#import cupy as cp\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "XujZHQqE6e4L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8f42aa0-8001-4f58-e2f3-b57d57294fe2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-md==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting fr-core-news-md==3.7.0\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-3.7.0/fr_core_news_md-3.7.0-py3-none-any.whl (45.8 MB)\n",
            "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from fr-core-news-md==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.1.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating helper functions to process the data"
      ],
      "metadata": {
        "id": "1xQiSwmB6km7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def load_data(file_path):\n",
        "    with open(file_path, encoding='utf-8') as file:\n",
        "        lines = [line.strip().lower() for line in file if line.strip()]\n",
        "    return lines\n",
        "\n",
        "def preprocess(lang_sentences, percentages, lang_models, device=\"CPU\"):\n",
        "    # in this preprocess function the data is added such that\n",
        "    # there is a small randomness added to it for training in the GANS\n",
        "    # i dont know why i added this but to test it might work like a bias value\n",
        "    data = []\n",
        "    if device == \"GPU\":\n",
        "      for sentence_0, sentence_1 in zip(*lang_sentences):\n",
        "          embedded_0 = lang_models[0](sentence_0).vector\n",
        "          embedded_1 = lang_models[1](sentence_1).vector\n",
        "          max_len = max(len(embedded_0), len(embedded_1))\n",
        "          # this is the gpu based code\n",
        "          pad_embedded_0 = cp.pad(cp.asarray(embedded_0), (0, max_len - len(embedded_0)), 'constant')\n",
        "          pad_embedded_1 = cp.pad(cp.asarray(embedded_1), (0, max_len - len(embedded_1)), 'constant')\n",
        "          random_mat = cp.random.rand(*embedded_0.shape)\n",
        "          full = pad_embedded_0 * percentages[0] + pad_embedded_1 * percentages[1] + random_mat\n",
        "          data.append(full)\n",
        "      return cp.array(data)\n",
        "    else:\n",
        "      # this is the cpu based code\n",
        "      for sentence_0, sentence_1 in zip(*lang_sentences):\n",
        "          embedded_0 = lang_models[0](sentence_0).vector\n",
        "          embedded_1 = lang_models[1](sentence_1).vector\n",
        "          max_len = max(len(embedded_0), len(embedded_1))\n",
        "          # this is the cpu based code\n",
        "          pad_embedded_0 = np.pad(embedded_0, (0, max_len - len(embedded_0)), 'constant')\n",
        "          pad_embedded_1 = np.pad(embedded_1, (0, max_len - len(embedded_1)), 'constant')\n",
        "          random_mat = np.random.rand(*embedded_0.shape)\n",
        "          full = pad_embedded_0 * percentages[0] + pad_embedded_1 * percentages[1] + random_mat\n",
        "          data.append(full)\n",
        "      return np.array(data)"
      ],
      "metadata": {
        "id": "o5qSMHmpBVvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PreProccessing and creating data"
      ],
      "metadata": {
        "id": "vVDAi9_J6y3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load English and French data\n",
        "english_sentences = load_data('europarl-v7.fr-en.en')\n",
        "french_sentences = load_data('europarl-v7.fr-en.fr')\n",
        "\n",
        "# load the spacy word embeddings for french and english\n",
        "spacy.require_gpu()\n",
        "spacy_embedding_en = spacy.load('en_core_web_md')\n",
        "spacy_embedding_fr = spacy.load('fr_core_news_md')\n",
        "\n",
        "# **mish mash** with 0.5 and 0.5 percentage points\n",
        "mashed_sentences = preprocess([english_sentences, french_sentences],\n",
        "                          [0.5, 0.5],\n",
        "                          [spacy_embedding_en, spacy_embedding_fr],\n",
        "                          \"GPU\")\n",
        "np.save('mashed_sentences_fr_en_50_50.npy', mashed_sentences) # saving data so doesnt haev to be loaded again\n",
        "# printing to see what the data looks like\n",
        "print(english_sentences[0])\n",
        "print(french_sentences[0])\n",
        "print(mashed_sentences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKe8T5Je6yPb",
        "outputId": "3c28a141-17f4-444e-cfa4-ff73988d8c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resumption of the session\n",
            "reprise de la session\n",
            "[-2.49061651  1.11504854  2.39136881  3.79393344  3.69417012  1.24119013\n",
            "  1.2501395   4.05214932  4.24175742 -1.30667777  5.60183789  2.2270884\n",
            " -4.08571278 -0.20129039  1.93792178  2.34961002  3.40335188  1.3221339\n",
            "  1.54315684 -0.85947136  0.83531318 -0.85715479 -1.59579728  2.56697813\n",
            "  1.02794241  2.84286097 -0.48122997  2.42148331  0.81854976  4.26659952\n",
            " -1.04953354 -0.11484184  1.52995699 -1.27412736 -1.66854097 -0.69063173\n",
            "  0.90881016  2.80558016 -1.04453607  2.75602544  0.79864483 -0.28106232\n",
            " -0.96821351  0.77351036 -1.21005747  1.01178247  1.49607794  0.74820235\n",
            "  0.25112318  0.06429124 -1.48974746  3.01765381 -0.32320162 -2.58223267\n",
            "  0.94201671  1.91856262 -0.91353967  1.17046314 -1.25212225 -1.95709339\n",
            "  1.43476395 -1.39199753 -1.3311984   1.45318164  1.93650032  2.3303438\n",
            " -1.97216938 -2.22071507  2.76307478  1.29644412  0.95721379  0.57003767\n",
            " -1.58387107 -1.29374905  0.34884804  1.78652949 -1.13213232  5.22314515\n",
            " -4.19962988 -1.37228894 -2.77744347  3.89811909 -0.51650707  2.92128646\n",
            "  1.12756724  2.67105594 -2.25925768 -2.93223028  0.77944852  1.7725847\n",
            "  0.07694845  1.96558185  1.86523509  0.19226047 -0.36648678  1.06932086\n",
            "  3.07884985  2.02944277 -0.42295471  1.57356768  2.37861169  2.61931767\n",
            "  4.31288889  3.38980649 -0.53682163  3.09799053  1.83642835 -0.96586106\n",
            "  1.06582142  0.41468947  2.57627192  1.68099753 -2.12504705  2.80134704\n",
            "  2.45558755  0.59851693  2.69203548  2.5810087  -0.29535226  0.51002207\n",
            " -1.28279955 -1.19763782  3.03472933  0.38981139  0.25584117 -3.23900455\n",
            "  1.95724026 -2.29893202  4.31006815 -0.26823523 -1.4647504   0.44700805\n",
            "  3.69657372  3.59807371 -0.81333797  2.99516418  0.53675389 -1.85027707\n",
            " -1.13525471  1.09421392  1.0025958   0.80200647  0.01741368  3.65184899\n",
            "  3.8147762   0.1269062  -3.09835929 -0.25471377  1.37740184  3.49746572\n",
            " -1.02766509  2.53018208  1.9497823   0.60300249  0.10323227  1.12259092\n",
            "  1.29055041 -3.20189289 -0.14890571  1.08688637  0.25542013  0.23503438\n",
            "  1.75981916  3.27189571  0.44928915 -0.88415895  0.32180662  0.85103529\n",
            "  2.69648997  0.80900389  1.43932283 -1.44340745  2.28497969 -1.84518153\n",
            " -0.58161262  0.23871684  2.72916688  0.29619351 -1.42512073  0.21505812\n",
            " -1.54882339  0.3963845   2.22305179  1.71221358  1.85661067  0.55632273\n",
            " -1.23232555  1.1894727   0.40647282  1.5486095   1.40942045 -0.2286639\n",
            "  3.00176738  2.7113819   2.44661001 -0.31186341 -0.96704903 -1.07684832\n",
            "  2.56053374  0.03972962  0.90552666 -0.35752855 -2.02915064 -2.68372081\n",
            "  4.13968977  2.80125131 -2.55813826  2.87182851  2.80254201  0.14270163\n",
            "  0.70355352  4.12320092 -2.96030386 -0.67679479  2.07368233  2.32642577\n",
            "  2.14278325 -2.16195256 -0.04145756  2.18427564 -2.32117998  5.17613547\n",
            "  0.94047564 -1.41115866 -1.65298746  2.40742934  0.87370302  2.82734585\n",
            "  0.19964967 -0.51768281  3.79752919 -1.47514368  0.53689132  3.05862276\n",
            "  3.40032598  2.36125351  0.89846324  2.03741373 -0.39798159 -2.74675248\n",
            "  0.87405241  2.397785   -1.11947785  2.14820511  0.47100103  1.98657767\n",
            " -1.07963021 -1.38463783 -0.77878892  1.34468649  2.80211194 -1.92401595\n",
            " -4.13464957 -0.03666325  0.47065468  0.64196568  2.41577742 -0.10290277\n",
            "  0.22770663  1.09933156  1.34665962  3.43209376  3.37164238  2.8232669\n",
            "  0.2819602  -0.59646692  2.05479424  0.20577151 -1.2564421   1.30949699\n",
            " -0.26421514 -0.07467374  2.8862592  -2.69967379  2.15933515  1.47401102\n",
            "  2.80442136 -0.49471564  0.64279033  1.18529063  1.93234231  2.57167111\n",
            "  4.73931458  0.65524208  1.82037118 -0.19246588  0.71252296  0.91903087\n",
            "  0.44628983 -1.08183911  0.50911875  2.70021249  0.23420754  3.51865216\n",
            " -2.0738619  -0.77254562 -0.82713663 -4.13050722  2.11182461 -0.0748824 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Here after processing the data it can be loaded with pytorch data loader object"
      ],
      "metadata": {
        "id": "xCCxfgeW8xQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MashedDataset(Dataset):\n",
        "  def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      return self.data[idx]\n",
        "\n",
        "mashed_sentences = np.load('mashed_sentences_fr_en_50_50.npy')\n",
        "mashed_sentences_dataset = MashedDataset(torch.from_numpy(mashed_sentences))\n",
        "# make sure to from numpy it\n",
        "batch_size = 64\n",
        "mashed_sentences_data = DataLoader(mashed_sentences_dataset,\n",
        "                                   batch_size=batch_size,\n",
        "                                   shuffle=True)"
      ],
      "metadata": {
        "id": "wtPus2ll81za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Here is the onehot outputs for characters and their encodings"
      ],
      "metadata": {
        "id": "edOXydVaNRl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_characters = ['a', 'à','â', 'æ', 'b', 'c', 'ç', 'd', 'e', 'é', 'è', 'ê',\n",
        "                      'ë', 'œ', 'f', 'g', 'h', 'i', 'î', 'ï', 'j', 'k', 'l',\n",
        "                      'm', 'n', 'o', 'ô', 'p', 'q', 'r', 's', 't', 'u', 'ù','û',\n",
        "                      'ü', 'v', 'w', 'x', 'y', 'ÿ' 'z', \"'\", ' ']\n",
        "                      # space character and ' included\n",
        "# this is both english and french characters discluding the overlap\n",
        "# capitals are **banned** and arent used\n",
        "# helper dictionaries for conversions\n",
        "char_to_index = {char: index for index, char in enumerate(one_hot_characters)}\n",
        "index_to_char = {index: char for index, char in enumerate(one_hot_characters)}\n"
      ],
      "metadata": {
        "id": "56Uuq_xGNXPb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generator Architecture\n",
        "\n",
        "The way this works is it will take in some length vector and then from it it will create the one hot matrix which represents the generated mish mashed sentence\n"
      ],
      "metadata": {
        "id": "A406yrbCOu05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_size=100, seq_length=60):\n",
        "        super(Generator, self).__init__()\n",
        "        self.seq_length = seq_length\n",
        "        self.gru = nn.GRU(input_size, 256, num_layers=1, batch_first=True)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear = nn.Linear(256, len(one_hot_characters))\n",
        "        self.softmax = nn.Softmax(dim=2)\n",
        "\n",
        "        # Initialize weights\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.GRU):\n",
        "                nn.init.xavier_uniform_(m.weight_ih_l0)\n",
        "                nn.init.xavier_uniform_(m.weight_hh_l0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "\n",
        "    def forward(self, x, temperature=1.0):\n",
        "    # Repeat the input noise vector seq_length times to create a sequence\n",
        "      x = x.repeat(1, self.seq_length, 1)\n",
        "      out, _ = self.gru(x)  # Only take the output, ignore the hidden state\n",
        "      out = self.relu(out)\n",
        "      out = self.linear(out)\n",
        "      out = out / temperature  # Apply the temperature parameter\n",
        "      out = self.softmax(out)\n",
        "      return out\n"
      ],
      "metadata": {
        "id": "JYJT6zESBoG-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Call the generator to see what it outputs untrained"
      ],
      "metadata": {
        "id": "DBJvX0LEVxWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate_sequence(generator, noise):\n",
        "    # Generate a sequence of one-hot vectors\n",
        "    one_hot_sequence = generator(noise, 1000)\n",
        "    # Convert the one-hot vectors to character indices\n",
        "    char_indices = torch.argmax(one_hot_sequence, dim=2)\n",
        "    # Convert the character indices to characters\n",
        "    sequence = ''.join(index_to_char[index.item()] for index in char_indices[0])\n",
        "    return sequence\n",
        "\n",
        "noise = torch.randn(1, 100)\n",
        "generator = Generator()\n",
        "sequence = generate_sequence(generator, noise)\n",
        "print(sequence)\n",
        "\n",
        "# ill embed this into english and then french and combine it to see what should\n",
        "# happen from it\n",
        "\n",
        "spacy_embedding_en = spacy.load('en_core_web_md')\n",
        "spacy_embedding_fr = spacy.load('fr_core_news_md')\n",
        "\n",
        "sequence_fr_embedding = spacy_embedding_fr(sequence).vector\n",
        "sequence_en_embedding = spacy_embedding_en(sequence).vector\n",
        "mashed_embedding = sequence_fr_embedding * 0.5 + sequence_en_embedding * 0.5\n",
        "print(mashed_embedding) # this might work\n",
        "# otherwise some other embedding scheme needs to be defined for the mashed language\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrjuraB0V0bF",
        "outputId": "eff0f192-3d50-41bd-a4a1-f7d70781c9c1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ççççççççüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüü\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Discriminator Architecture\n",
        "\n",
        "This has to figure out if something is real or fake"
      ],
      "metadata": {
        "id": "aWaTjcFcOwzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_size=256, hidden_size=128):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.gru = nn.GRU(input_size, hidden_size, num_layers=1, batch_first=True)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear = nn.Linear(hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.gru(x)  # Only take the output, ignore the hidden state\n",
        "        out = self.relu(out)\n",
        "        out = self.linear(out[:, -1, :])  # Only take the last output of the sequence\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "_KVJQO-hOzQu"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing the untrained discriminator on the previous embeddings"
      ],
      "metadata": {
        "id": "_MnSlVwlbPhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the numpy array to a PyTorch tensor\n",
        "mashed_embedding = torch.from_numpy(mashed_embedding)\n",
        "\n",
        "# Add an extra dimension for the batch size and sequence length if necessary\n",
        "if len(mashed_embedding.shape) == 1:\n",
        "    mashed_embedding = mashed_embedding.view(1, 1, -1)\n",
        "\n",
        "# Instantiate the discriminator\n",
        "discriminator = Discriminator(input_size=mashed_embedding.shape[-1])\n",
        "\n",
        "# Pass the embeddings through the discriminator\n",
        "prob = discriminator(mashed_embedding)\n",
        "\n",
        "print(prob.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDyeqQ9-bUdR",
        "outputId": "1234bee1-abc8-4e40-94d6-366dd63531eb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4920]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Setup"
      ],
      "metadata": {
        "id": "wSQUUjXCO5en"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(DEVICE)\n",
        "D = Discriminator().to(DEVICE)\n",
        "G = Generator().to(DEVICE)\n",
        "# shoving hopefully everything to the gpu\n",
        "\n",
        "max_epoch = 50 # going for 50 epochs\n",
        "step = 0 # step through the data\n",
        "n_noise = 100 # size of noise vector\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "D_opt = torch.optim.Adam(D.parameters(), lr=10e-4, betas=(0.5, 0.999))\n",
        "G_opt = torch.optim.Adam(G.parameters(), lr=10e-4, betas=(0.5, 0.999))\n",
        "# optimizers for both the discriminator and generator alongside a\n",
        "# binary cross entropy loss\n",
        "\n",
        "# We will denote real images as 1s and fake images as 0s\n",
        "# This is why we needed to drop the last batch of the data loader\n",
        "D_labels = torch.ones([batch_size, 1]).to(DEVICE) # Discriminator label: real\n",
        "D_fakes = torch.zeros([batch_size, 1]).to(DEVICE) # Discriminator Label: fake"
      ],
      "metadata": {
        "id": "Wg-pAhhbO7du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Loop"
      ],
      "metadata": {
        "id": "xRY_j8alO1lJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# import pyplot to plot images\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "    for idx, (images, labels) in enumerate(data_loader):\n",
        "        # Training Discriminator\n",
        "        x = images.to(DEVICE)\n",
        "        x_outputs = D(x) # input includes labels\n",
        "        D_x_loss = criterion(x_outputs, D_labels) # Discriminator loss for real images\n",
        "\n",
        "        z = torch.randn(batch_size, n_noise).to(DEVICE)\n",
        "        z_outputs = D(G(z)) # input to both generator and discriminator includes labels\n",
        "        D_z_loss = criterion(z_outputs, D_fakes) # Discriminator loss for fake images\n",
        "        D_loss = D_x_loss + D_z_loss # Total Discriminator loss\n",
        "\n",
        "        D.zero_grad()\n",
        "        D_loss.backward()\n",
        "        D_opt.step()\n",
        "        # updating the discriminator model\n",
        "\n",
        "        # Training Generator\n",
        "        z = torch.randn(batch_size, n_noise).to(DEVICE) # creating the random vector alongside the batch proper\n",
        "        z_outputs = D(G(z))\n",
        "        G_loss = -1 * criterion(z_outputs, D_fakes) # Generator loss is negative disciminator loss\n",
        "\n",
        "        G.zero_grad()\n",
        "        G_loss.backward()\n",
        "        G_opt.step()\n",
        "        # updating the generator model\n",
        "\n",
        "        if step % 500 == 0:\n",
        "            print('Epoch: {}/{}, Step: {}, D Loss: {}, G Loss: {}'.format(epoch, max_epoch, step, D_loss.item(), G_loss.item()))\n",
        "            # done to view teh loss\n",
        "        step += 1\n",
        "\n",
        "    if epoch+1 in [1, 10, 30, 50]:\n",
        "      # if in the 1st (done for making sure everything is good)\n",
        "      # or the 10th or 30th or 50th epoch then display what the\n",
        "      # generator has so far\n",
        "      G.eval()  # eval mode\n",
        "      img = get_sample_image(G, DEVICE, n_noise)\n",
        "      print(\"got images\")\n",
        "      plt.imshow(img, cmap='gray')\n",
        "      plt.show()\n",
        "      # show the plot from get sample images\n",
        "      G.train()\n",
        "      # back to trianing the genrator\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IADUvzIQBrAS",
        "outputId": "d03e335a-e1a2-42ec-e478-2eb49f82e144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 764ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Epoch 100/1000 [D loss: 2.427980661392212, acc.: 50.0] [G loss: 0.017235977575182915]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Epoch 200/1000 [D loss: 0.3459985852241516, acc.: 100.0] [G loss: 0.7180488705635071]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Epoch 300/1000 [D loss: 0.6472909450531006, acc.: 50.0] [G loss: 0.36351633071899414]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Epoch 400/1000 [D loss: 0.7177719473838806, acc.: 50.0] [G loss: 0.3367061913013458]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Epoch 500/1000 [D loss: 0.6133091449737549, acc.: 50.0] [G loss: 0.46426188945770264]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Epoch 600/1000 [D loss: 0.5504212379455566, acc.: 50.0] [G loss: 0.5941251516342163]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Epoch 700/1000 [D loss: 0.3202908933162689, acc.: 100.0] [G loss: 0.7495474219322205]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Epoch 800/1000 [D loss: 0.34345370531082153, acc.: 100.0] [G loss: 0.7094087600708008]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "Epoch 900/1000 [D loss: 0.590474009513855, acc.: 50.0] [G loss: 0.3796089291572571]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Epoch 1000/1000 [D loss: 0.8391926884651184, acc.: 50.0] [G loss: 0.223337322473526]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "gan.generator.save('generator_model.h5')\n",
        "gan.discriminator.save('discriminator_model.h5')\n",
        "\n",
        "# Plotting the training progress (you need to modify the training loop to store loss values)\n",
        "plt.plot(discriminator_loss, label='Discriminator Loss')\n",
        "plt.plot(generator_loss, label='Generator Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "3H98dkVzB3Po",
        "outputId": "c161645f-4066-4129-fad7-80be79dac4a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(generator, tokenizer, latent_dim, num_sentences):\n",
        "    # Generate noise.\n",
        "    noise = np.random.normal(0, 1, (num_sentences, latent_dim))\n",
        "    # Generate token indices from the noise using the generator.\n",
        "    generated_sequences = generator.predict(noise)\n",
        "    # Convert the output probabilities to token indices.\n",
        "    generated_sequences = np.argmax(generated_sequences, axis=-1)\n",
        "\n",
        "    # Initialize an empty list to hold the generated sentences.\n",
        "    text_batch = []\n",
        "\n",
        "    # Process each sequence to convert token indices to words.\n",
        "    for seq in generated_sequences:\n",
        "        # Filter out zeros (unwanted tokens) from the sequence.\n",
        "        filtered_indices = seq[seq != 0]\n",
        "        # Convert non-zero indices to words using the tokenizer.\n",
        "        words = [tokenizer.index_word.get(i, '') for i in filtered_indices]\n",
        "        # Join the words to form a sentence.\n",
        "        sentence = ' '.join(words).strip()\n",
        "        # Add the sentence to the batch of generated text.\n",
        "        text_batch.append(sentence)\n",
        "\n",
        "    return text_batch\n",
        "\n",
        "# Example usage of the function to generate text.\n",
        "generated_text = generate_text(gan.generator, tokenizer, latent_dim=100, num_sentences=15)\n",
        "for text in generated_text:\n",
        "    print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDc2irv_F_Th",
        "outputId": "82f23c7f-bc45-49f3-aa56-5de77592e32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "nous\n",
            "nous\n",
            "nous\n",
            "nous\n",
            "nous\n",
            "nous\n",
            "nous\n",
            "nous\n",
            "nous\n",
            "nous\n",
            "nous\n",
            "nous\n",
            "nous\n",
            "nous\n",
            "nous\n"
          ]
        }
      ]
    }
  ]
}